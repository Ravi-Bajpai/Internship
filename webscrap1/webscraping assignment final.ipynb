{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808f6345",
   "metadata": {},
   "source": [
    "# 1 HEADER TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e8dfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "819cb806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "810de3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3daaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_tag=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    header_tag.append(i.text)\n",
    "    \n",
    "header_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafa5844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADER TAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HEADER TAGS\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'HEADER TAGS':header_tag})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7be67",
   "metadata": {},
   "source": [
    "# 2 IMDB’s Top rated 100 movies’ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0c6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c80855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a3ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "592891e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      1.      The Shawshank Redemption(1994)',\n",
       " '      2.      The Godfather(1972)',\n",
       " '      3.      The Dark Knight(2008)',\n",
       " '      4.      The Godfather Part II(1974)',\n",
       " '      5.      12 Angry Men(1957)',\n",
       " \"      6.      Schindler's List(1993)\",\n",
       " '      7.      The Lord of the Rings: The Return of the King(2003)',\n",
       " '      8.      Pulp Fiction(1994)',\n",
       " '      9.      The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '      10.      Il buono, il brutto, il cattivo(1966)',\n",
       " '      11.      Forrest Gump(1994)',\n",
       " '      12.      Fight Club(1999)',\n",
       " '      13.      Inception(2010)',\n",
       " '      14.      The Lord of the Rings: The Two Towers(2002)',\n",
       " '      15.      The Empire Strikes Back(1980)',\n",
       " '      16.      The Matrix(1999)',\n",
       " '      17.      Goodfellas(1990)',\n",
       " \"      18.      One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '      19.      Se7en(1995)',\n",
       " '      20.      Shichinin no samurai(1954)',\n",
       " \"      21.      It's a Wonderful Life(1946)\",\n",
       " '      22.      The Silence of the Lambs(1991)',\n",
       " '      23.      Cidade de Deus(2002)',\n",
       " '      24.      Saving Private Ryan(1998)',\n",
       " '      25.      La vita è bella(1997)',\n",
       " '      26.      The Green Mile(1999)',\n",
       " '      27.      Interstellar(2014)',\n",
       " '      28.      Star Wars(1977)',\n",
       " '      29.      Terminator 2: Judgment Day(1991)',\n",
       " '      30.      Back to the Future(1985)',\n",
       " '      31.      Sen to Chihiro no kamikakushi(2001)',\n",
       " '      32.      Psycho(1960)',\n",
       " '      33.      The Pianist(2002)',\n",
       " '      34.      Léon(1994)',\n",
       " '      35.      Gisaengchung(2019)',\n",
       " '      36.      The Lion King(1994)',\n",
       " '      37.      Gladiator(2000)',\n",
       " '      38.      American History X(1998)',\n",
       " '      39.      The Usual Suspects(1995)',\n",
       " '      40.      The Departed(2006)',\n",
       " '      41.      The Prestige(2006)',\n",
       " '      42.      Casablanca(1942)',\n",
       " '      43.      Whiplash(2014)',\n",
       " '      44.      Top Gun: Maverick(2022)',\n",
       " '      45.      The Intouchables(2011)',\n",
       " '      46.      Modern Times(1936)',\n",
       " '      47.      Seppuku(1962)',\n",
       " '      48.      Hotaru no haka(1988)',\n",
       " '      49.      Once Upon a Time in the West(1968)',\n",
       " '      50.      Rear Window(1954)',\n",
       " '      51.      Alien(1979)',\n",
       " '      52.      City Lights(1931)',\n",
       " '      53.      Nuovo Cinema Paradiso(1988)',\n",
       " '      54.      Memento(2000)',\n",
       " '      55.      Apocalypse Now(1979)',\n",
       " '      56.      Raiders of the Lost Ark(1981)',\n",
       " '      57.      Django Unchained(2012)',\n",
       " '      58.      WALL·E(2008)',\n",
       " '      59.      The Lives of Others(2006)',\n",
       " '      60.      Sunset Blvd.(1950)',\n",
       " '      61.      Paths of Glory(1957)',\n",
       " '      62.      The Shining(1980)',\n",
       " '      63.      The Great Dictator(1940)',\n",
       " '      64.      Witness for the Prosecution(1957)',\n",
       " '      65.      Avengers: Infinity War(2018)',\n",
       " '      66.      Aliens(1986)',\n",
       " '      67.      American Beauty(1999)',\n",
       " '      68.      Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)',\n",
       " '      69.      Spider-Man: Into the Spider-Verse(2018)',\n",
       " '      70.      The Dark Knight Rises(2012)',\n",
       " '      71.      Oldeuboi(2003)',\n",
       " '      72.      Joker(2019)',\n",
       " '      73.      Amadeus(1984)',\n",
       " '      74.      Braveheart(1995)',\n",
       " '      75.      Toy Story(1995)',\n",
       " '      76.      Coco(2017)',\n",
       " '      77.      Das Boot(1981)',\n",
       " '      78.      Inglourious Basterds(2009)',\n",
       " '      79.      Mononoke-hime(1997)',\n",
       " '      80.      Avengers: Endgame(2019)',\n",
       " '      81.      Once Upon a Time in America(1984)',\n",
       " '      82.      Good Will Hunting(1997)',\n",
       " '      83.      Requiem for a Dream(2000)',\n",
       " '      84.      Toy Story 3(2010)',\n",
       " '      85.      Kimi no na wa.(2016)',\n",
       " \"      86.      Singin' in the Rain(1952)\",\n",
       " '      87.      3 Idiots(2009)',\n",
       " '      88.      Star Wars: Episode VI - Return of the Jedi(1983)',\n",
       " '      89.      2001: A Space Odyssey(1968)',\n",
       " '      90.      Eternal Sunshine of the Spotless Mind(2004)',\n",
       " '      91.      Reservoir Dogs(1992)',\n",
       " '      92.      Tengoku to jigoku(1963)',\n",
       " '      93.      Capharnaüm(2018)',\n",
       " '      94.      Citizen Kane(1941)',\n",
       " '      95.      Lawrence of Arabia(1962)',\n",
       " '      96.      Jagten(2012)',\n",
       " '      97.      M - Eine Stadt sucht einen Mörder(1931)',\n",
       " '      98.      North by Northwest(1959)',\n",
       " '      99.      Vertigo(1958)',\n",
       " \"      100.      Le fabuleux destin d'Amélie Poulain(2001)\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "name[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b3581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rate.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "rate[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843261b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(2001)',\n",
       " '(1966)',\n",
       " '(1994)',\n",
       " '(1999)',\n",
       " '(2010)',\n",
       " '(2002)',\n",
       " '(1980)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1975)',\n",
       " '(1995)',\n",
       " '(1954)',\n",
       " '(1946)',\n",
       " '(1991)',\n",
       " '(2002)',\n",
       " '(1998)',\n",
       " '(1997)',\n",
       " '(1999)',\n",
       " '(2014)',\n",
       " '(1977)',\n",
       " '(1991)',\n",
       " '(1985)',\n",
       " '(2001)',\n",
       " '(1960)',\n",
       " '(2002)',\n",
       " '(1994)',\n",
       " '(2019)',\n",
       " '(1994)',\n",
       " '(2000)',\n",
       " '(1998)',\n",
       " '(1995)',\n",
       " '(2006)',\n",
       " '(2006)',\n",
       " '(1942)',\n",
       " '(2014)',\n",
       " '(2022)',\n",
       " '(2011)',\n",
       " '(1936)',\n",
       " '(1962)',\n",
       " '(1988)',\n",
       " '(1968)',\n",
       " '(1954)',\n",
       " '(1979)',\n",
       " '(1931)',\n",
       " '(1988)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2012)',\n",
       " '(2008)',\n",
       " '(2006)',\n",
       " '(1950)',\n",
       " '(1957)',\n",
       " '(1980)',\n",
       " '(1940)',\n",
       " '(1957)',\n",
       " '(2018)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " '(1964)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2003)',\n",
       " '(2019)',\n",
       " '(1984)',\n",
       " '(1995)',\n",
       " '(1995)',\n",
       " '(2017)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(1997)',\n",
       " '(2019)',\n",
       " '(1984)',\n",
       " '(1997)',\n",
       " '(2000)',\n",
       " '(2010)',\n",
       " '(2016)',\n",
       " '(1952)',\n",
       " '(2009)',\n",
       " '(1983)',\n",
       " '(1968)',\n",
       " '(2004)',\n",
       " '(1992)',\n",
       " '(1963)',\n",
       " '(2018)',\n",
       " '(1941)',\n",
       " '(1962)',\n",
       " '(2012)',\n",
       " '(1931)',\n",
       " '(1959)',\n",
       " '(1958)',\n",
       " '(2001)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yorl=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    yorl.append(i.text)\n",
    "    \n",
    "yorl[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee83352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      The Shawshank Redemption(1994)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      The Godfather Part II(1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      12 Angry Men(1957)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Jagten(2012)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      M - Eine Stadt sucht einen Mörd...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      North by Northwest(1959)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Vertigo(1958)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Le fabuleux destin d'Amélie Po...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name Rating year of release\n",
       "0              1.      The Shawshank Redemption(1994)    9.2          (1994)\n",
       "1                         2.      The Godfather(1972)    9.2          (1972)\n",
       "2                       3.      The Dark Knight(2008)    9.0          (2008)\n",
       "3                 4.      The Godfather Part II(1974)    9.0          (1974)\n",
       "4                          5.      12 Angry Men(1957)    8.9          (1957)\n",
       "..                                                ...    ...             ...\n",
       "95                              96.      Jagten(2012)    8.3          (2012)\n",
       "96        97.      M - Eine Stadt sucht einen Mörd...    8.3          (1931)\n",
       "97                  98.      North by Northwest(1959)    8.3          (1959)\n",
       "98                             99.      Vertigo(1958)    8.2          (1958)\n",
       "99        100.      Le fabuleux destin d'Amélie Po...    8.2          (2001)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name':name,'Rating':rate,'year of release':yorl})\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e2acb",
   "metadata": {},
   "source": [
    "# 3 IMDB’s Top rated 100 Indian movies’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f4c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c81515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.imdb.com/india/top-rated-indian-movies')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404e3177",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79750b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      1.      Jai Bhim(2021)',\n",
       " '      2.      Anbe Sivam(2003)',\n",
       " '      3.      Golmaal(1979)',\n",
       " '      4.      Nayakan(1987)',\n",
       " '      5.      Pariyerum Perumal(2018)',\n",
       " '      6.      3 Idiots(2009)',\n",
       " '      7.      Apur Sansar(1959)',\n",
       " '      8.      Manichitrathazhu(1993)',\n",
       " '      9.      Black Friday(2004)',\n",
       " '      10.      Kumbalangi Nights(2019)',\n",
       " '      11.      C/o Kancharapalem(2018)',\n",
       " '      12.      Taare Zameen Par(2007)',\n",
       " '      13.      #Home(2021)',\n",
       " '      14.      Vikram(2022)',\n",
       " '      15.      Soorarai Pottru(2020)',\n",
       " '      16.      Dangal(2016)',\n",
       " '      17.      Kireedam(1989)',\n",
       " '      18.      Kaithi(2019)',\n",
       " '      19.      Jersey(2019)',\n",
       " '      20.      Thevar Magan(1992)',\n",
       " '      21.      Pather Panchali(1955)',\n",
       " '      22.      Asuran(2019)',\n",
       " '      23.      96(2018)',\n",
       " '      24.      Visaaranai(2015)',\n",
       " '      25.      Thalapathi(1991)',\n",
       " '      26.      Natsamrat(2016)',\n",
       " '      27.      Sarpatta Parambarai(2021)',\n",
       " '      28.      Drishyam 2(2021)',\n",
       " '      29.      Sardar Udham(2021)',\n",
       " '      30.      Thani Oruvan(2015)',\n",
       " '      31.      Aparajito(1956)',\n",
       " '      32.      Vada Chennai(2018)',\n",
       " '      33.      Jaane Bhi Do Yaaro(1983)',\n",
       " '      34.      Khosla Ka Ghosla!(2006)',\n",
       " '      35.      Drishyam(2013)',\n",
       " '      36.      Chupke Chupke(1975)',\n",
       " '      37.      Peranbu(2018)',\n",
       " '      38.      Agent Sai Srinivasa Athreya(2019)',\n",
       " '      39.      Anniyan(2005)',\n",
       " '      40.      Mahanati(2018)',\n",
       " '      41.      Super Deluxe(2019)',\n",
       " '      42.      Bangalore Days(2014)',\n",
       " '      43.      Satya(1998)',\n",
       " '      44.      Premam(2015)',\n",
       " '      45.      Ratsasan(2018)',\n",
       " '      46.      Devasuram(1993)',\n",
       " '      47.      Bhaag Milkha Bhaag(2013)',\n",
       " '      48.      Gangs of Wasseypur(2012)',\n",
       " '      49.      Aruvi(2016)',\n",
       " '      50.      Andhadhun(2018)',\n",
       " '      51.      Drishyam(2015)',\n",
       " '      52.      Kannathil Muthamittal(2002)',\n",
       " '      53.      Guide(1965)',\n",
       " '      54.      Shahid(2012)',\n",
       " '      55.      Chithram(1988)',\n",
       " '      56.      Iruvar(1997)',\n",
       " '      57.      Sairat(2016)',\n",
       " '      58.      Zindagi Na Milegi Dobara(2011)',\n",
       " '      59.      Paan Singh Tomar(2012)',\n",
       " '      60.      Vikram Vedha(2017)',\n",
       " '      61.      Tumbbad(2018)',\n",
       " '      62.      Mudhalvan(1999)',\n",
       " '      63.      Dhuruvangal Pathinaaru(2016)',\n",
       " '      64.      Black(2005)',\n",
       " '      65.      Chhichhore(2019)',\n",
       " '      66.      Spadikam(1995)',\n",
       " '      67.      Swades: We, the People(2004)',\n",
       " '      68.      Chak De! India(2007)',\n",
       " '      69.      Jo Jeeta Wohi Sikandar(1992)',\n",
       " '      70.      Pudhu Pettai(2006)',\n",
       " '      71.      Papanasam(2015)',\n",
       " '      72.      Pyaasa(1957)',\n",
       " '      73.      Soodhu Kavvum(2013)',\n",
       " '      74.      PK(2014)',\n",
       " '      75.      Munna Bhai M.B.B.S.(2003)',\n",
       " '      76.      Mandela(2021)',\n",
       " '      77.      Article 15(2019)',\n",
       " '      78.      Queen(2013)',\n",
       " '      79.      Talvar(2015)',\n",
       " '      80.      Uri: The Surgical Strike(2019)',\n",
       " '      81.      Kaakkaa Muttai(2014)',\n",
       " '      82.      OMG: Oh My God!(2012)',\n",
       " '      83.      Lagaan: Once Upon a Time in India(2001)',\n",
       " '      84.      Jigarthanda(2014)',\n",
       " '      85.      Sarfarosh(1999)',\n",
       " '      86.      Udaan(2010)',\n",
       " '      87.      Barfi!(2012)',\n",
       " '      88.      Theeran Adhigaaram Ondru(2017)',\n",
       " '      89.      Sholay(1975)',\n",
       " '      90.      Ustad Hotel(2012)',\n",
       " '      91.      Hera Pheri(2000)',\n",
       " '      92.      The Legend of Bhagat Singh(2002)',\n",
       " '      93.      Angoor(1982)',\n",
       " '      94.      Rang De Basanti(2006)',\n",
       " '      95.      Baasha(1995)',\n",
       " '      96.      Masaan(2015)',\n",
       " '      97.      Kahaani(2012)',\n",
       " '      98.      Baahubali 2: The Conclusion(2017)',\n",
       " '      99.      Dil Chahta Hai(2001)',\n",
       " '      100.      Maheshinte Prathikaaram(2016)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "name[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f43c2433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rate.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "rate[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dab6c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2021)',\n",
       " '(2003)',\n",
       " '(1979)',\n",
       " '(1987)',\n",
       " '(2018)',\n",
       " '(2009)',\n",
       " '(1959)',\n",
       " '(1993)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2007)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(2020)',\n",
       " '(2016)',\n",
       " '(1989)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(1992)',\n",
       " '(1955)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(1991)',\n",
       " '(2016)',\n",
       " '(2021)',\n",
       " '(2021)',\n",
       " '(2021)',\n",
       " '(2015)',\n",
       " '(1956)',\n",
       " '(2018)',\n",
       " '(1983)',\n",
       " '(2006)',\n",
       " '(2013)',\n",
       " '(1975)',\n",
       " '(2018)',\n",
       " '(2019)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(1998)',\n",
       " '(2015)',\n",
       " '(2018)',\n",
       " '(1993)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(2016)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(2002)',\n",
       " '(1965)',\n",
       " '(2012)',\n",
       " '(1988)',\n",
       " '(1997)',\n",
       " '(2016)',\n",
       " '(2011)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2018)',\n",
       " '(1999)',\n",
       " '(2016)',\n",
       " '(2005)',\n",
       " '(2019)',\n",
       " '(1995)',\n",
       " '(2004)',\n",
       " '(2007)',\n",
       " '(1992)',\n",
       " '(2006)',\n",
       " '(2015)',\n",
       " '(1957)',\n",
       " '(2013)',\n",
       " '(2014)',\n",
       " '(2003)',\n",
       " '(2021)',\n",
       " '(2019)',\n",
       " '(2013)',\n",
       " '(2015)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(2001)',\n",
       " '(2014)',\n",
       " '(1999)',\n",
       " '(2010)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(1975)',\n",
       " '(2012)',\n",
       " '(2000)',\n",
       " '(2002)',\n",
       " '(1982)',\n",
       " '(2006)',\n",
       " '(1995)',\n",
       " '(2015)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2001)',\n",
       " '(2016)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yorl=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    yorl.append(i.text)\n",
    "    \n",
    "yorl[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d740685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Jai Bhim(2021)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Anbe Sivam(2003)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Golmaal(1979)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Nayakan(1987)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      Pariyerum Perumal(2018)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Masaan(2015)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      Kahaani(2012)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Baahubali 2: The Conclusion(2017)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Dil Chahta Hai(2001)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Maheshinte Prathikaaram(2016)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Rating year of release\n",
       "0                             1.      Jai Bhim(2021)    8.4          (2021)\n",
       "1                           2.      Anbe Sivam(2003)    8.4          (2003)\n",
       "2                              3.      Golmaal(1979)    8.4          (1979)\n",
       "3                              4.      Nayakan(1987)    8.4          (1987)\n",
       "4                    5.      Pariyerum Perumal(2018)    8.4          (2018)\n",
       "..                                               ...    ...             ...\n",
       "95                             96.      Masaan(2015)    8.0          (2015)\n",
       "96                            97.      Kahaani(2012)    8.0          (2012)\n",
       "97        98.      Baahubali 2: The Conclusion(2017)    8.0          (2017)\n",
       "98                     99.      Dil Chahta Hai(2001)    8.0          (2001)\n",
       "99           100.      Maheshinte Prathikaaram(2016)    8.0          (2016)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name':name,'Rating':rate,'year of release':yorl})\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15827b1",
   "metadata": {},
   "source": [
    "# 4 PRESIDENT OF INDIA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c906c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3467b83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af91d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "362b17d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Pranab Mukherjee ',\n",
       " 'Smt Pratibha Devisingh Patil ',\n",
       " 'DR. A.P.J. Abdul Kalam ',\n",
       " 'Shri K. R. Narayanan ',\n",
       " 'Dr Shankar Dayal Sharma ',\n",
       " 'Shri R Venkataraman ',\n",
       " 'Giani Zail Singh ',\n",
       " 'Shri Neelam Sanjiva Reddy ',\n",
       " 'Dr. Fakhruddin Ali Ahmed ',\n",
       " 'Shri Varahagiri Venkata Giri ',\n",
       " 'Dr. Zakir Husain ',\n",
       " 'Dr. Sarvepalli Radhakrishnan ',\n",
       " 'Dr. Rajendra Prasad ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nop=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    nop.append(i.find(\"h3\").text.split(\"(\")[0])\n",
    "    \n",
    "nop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c911141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25 July, 2012 to 25 July, 2017 ',\n",
       " ' 25 July, 2007 to 25 July, 2012 ',\n",
       " ' 25 July, 2002 to 25 July, 2007 ',\n",
       " ' 25 July, 1997 to 25 July, 2002 ',\n",
       " ' 25 July, 1992 to 25 July, 1997 ',\n",
       " ' 25 July, 1987 to 25 July, 1992 ',\n",
       " ' 25 July, 1982 to 25 July, 1987 ',\n",
       " ' 25 July, 1977 to 25 July, 1982 ',\n",
       " ' 24 August, 1974 to 11 February, 1977',\n",
       " ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " ' 13 May, 1967 to 3 May, 1969',\n",
       " ' 13 May, 1962 to 13 May, 1967',\n",
       " ' 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office=[]\n",
    "for i in soup.find_all(\"div\",class_=\"presidentListing\"):\n",
    "\n",
    "     office.append(i.find_all(\"p\")[0].text.split(\":\")[1])\n",
    "    \n",
    "office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075b6f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13\n"
     ]
    }
   ],
   "source": [
    "print(len(nop),len(office))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b5dfa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME OF PRESIDENT</th>\n",
       "      <th>TERM OF OFFICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NAME OF PRESIDENT  \\\n",
       "0          Shri Pranab Mukherjee    \n",
       "1   Smt Pratibha Devisingh Patil    \n",
       "2         DR. A.P.J. Abdul Kalam    \n",
       "3           Shri K. R. Narayanan    \n",
       "4        Dr Shankar Dayal Sharma    \n",
       "5            Shri R Venkataraman    \n",
       "6               Giani Zail Singh    \n",
       "7      Shri Neelam Sanjiva Reddy    \n",
       "8       Dr. Fakhruddin Ali Ahmed    \n",
       "9   Shri Varahagiri Venkata Giri    \n",
       "10              Dr. Zakir Husain    \n",
       "11  Dr. Sarvepalli Radhakrishnan    \n",
       "12           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       TERM OF OFFICE  \n",
       "0                     25 July, 2012 to 25 July, 2017   \n",
       "1                     25 July, 2007 to 25 July, 2012   \n",
       "2                     25 July, 2002 to 25 July, 2007   \n",
       "3                     25 July, 1997 to 25 July, 2002   \n",
       "4                     25 July, 1992 to 25 July, 1997   \n",
       "5                     25 July, 1987 to 25 July, 1992   \n",
       "6                     25 July, 1982 to 25 July, 1987   \n",
       "7                     25 July, 1977 to 25 July, 1982   \n",
       "8                24 August, 1974 to 11 February, 1977  \n",
       "9    3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "10                        13 May, 1967 to 3 May, 1969  \n",
       "11                       13 May, 1962 to 13 May, 1967  \n",
       "12                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.DataFrame({'NAME OF PRESIDENT':nop,'TERM OF OFFICE':office})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3891fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11435bf9",
   "metadata": {},
   "source": [
    "# ICC cricket teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318db11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffd324f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f99d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8a5b0cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Pakistan',\n",
       " 'India',\n",
       " 'Australia',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    \n",
    "     country.append(i.text)\n",
    "    \n",
    "country[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cc505aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "match.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bf74ece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,505'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "point.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "642fec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12',\n",
       " '1,505',\n",
       " '22',\n",
       " '2,756',\n",
       " '19',\n",
       " '2,005',\n",
       " '22',\n",
       " '2,304',\n",
       " '23',\n",
       " '2,325',\n",
       " '19',\n",
       " '1,872',\n",
       " '24',\n",
       " '2,275',\n",
       " '29',\n",
       " '2,658',\n",
       " '32',\n",
       " '2,306',\n",
       " '18',\n",
       " '1,238',\n",
       " '20',\n",
       " '1,083',\n",
       " '18',\n",
       " '814',\n",
       " '19',\n",
       " '724',\n",
       " '18',\n",
       " '603',\n",
       " '17',\n",
       " '539',\n",
       " '30',\n",
       " '919',\n",
       " '20',\n",
       " '544',\n",
       " '11',\n",
       " '246',\n",
       " '18',\n",
       " '298',\n",
       " '22',\n",
       " '134']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "matches=[]\n",
    "matches.append(match.text)\n",
    "matches.append(point.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    \n",
    "    matches.append(i.text)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a42e9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                            125                            '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "first_rating.text.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20165b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            125                            ',\n",
       " '125',\n",
       " '106',\n",
       " '105',\n",
       " '101',\n",
       " '99',\n",
       " '95',\n",
       " '92',\n",
       " '72',\n",
       " '69']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "rating.append(first_rating.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4d30ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 40 20\n"
     ]
    }
   ],
   "source": [
    "print(len(country),len(matches),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d3722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41fe2a57",
   "metadata": {},
   "source": [
    "# Top 10 ODI Batsmen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b80ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7d3b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi?at=2022-06-30\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e49096c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6782679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Babar Azam'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_player=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "first_player.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d466e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Imam-ul-Haq',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Quinton de Kock',\n",
       " 'Ross Taylor',\n",
       " 'Rassie van der Dussen',\n",
       " 'Jonny Bairstow',\n",
       " 'David Warner',\n",
       " 'Shai Hope']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player=[]\n",
    "player.append(first_player.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    player.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbd802a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPAK\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_team=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "y=first_team.text.split(\" \")[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60f152ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nPAK\\n                            892\\n',\n",
       " 'PAK',\n",
       " 'IND',\n",
       " 'IND',\n",
       " 'SA',\n",
       " 'NZ',\n",
       " 'SA',\n",
       " 'ENG',\n",
       " 'AUS',\n",
       " 'WI']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "team.append(first_team.text)\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7beef846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'892'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rating=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "f=first_rating.text\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bc1a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['892', '815', '811', '791', '789', '775', '769', '752', '737', '718']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "rating.append(f)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd37fef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>\\n\\nPAK\\n                            892\\n</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  player                                        team Rating\n",
       "0             Babar Azam  \\n\\nPAK\\n                            892\\n    892\n",
       "1            Imam-ul-Haq                                         PAK    815\n",
       "2            Virat Kohli                                         IND    811\n",
       "3           Rohit Sharma                                         IND    791\n",
       "4        Quinton de Kock                                          SA    789\n",
       "5            Ross Taylor                                          NZ    775\n",
       "6  Rassie van der Dussen                                          SA    769\n",
       "7         Jonny Bairstow                                         ENG    752\n",
       "8           David Warner                                         AUS    737\n",
       "9              Shai Hope                                          WI    718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'player':player,'team':team,'Rating':rating})\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0664c0",
   "metadata": {},
   "source": [
    "# Top 10 ODI bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7e9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1612a409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd876bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f03400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_player1=[]\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name\"):\n",
    "    first_player1.append(i.text)\n",
    "\n",
    "fp=first_player1[1:2]\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82166a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Trent Boult'],\n",
       " 'Matt Henry',\n",
       " 'Shaheen Afridi',\n",
       " 'Chris Woakes',\n",
       " 'Jasprit Bumrah',\n",
       " 'Josh Hazlewood',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Mehedi Hasan',\n",
       " 'Mohammad Nabi',\n",
       " 'Shakib Al Hasan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):# players name\n",
    "\n",
    "        players.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "players.insert(9,fp)\n",
    "players[9:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c9af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4b3c556",
   "metadata": {},
   "source": [
    "# Top 10 ODI teams women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe5e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec08cd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbeb862",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33152794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Pakistan',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    \n",
    "     country.append(i.text)\n",
    "    \n",
    "country[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bff7ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "match.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7763a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4,837'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "point.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bde3be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29',\n",
       " '4,837',\n",
       " '32',\n",
       " '3,949',\n",
       " '30',\n",
       " '3,531',\n",
       " '29',\n",
       " '2,889',\n",
       " '31',\n",
       " '3,019',\n",
       " '30',\n",
       " '2,768',\n",
       " '12',\n",
       " '930',\n",
       " '30',\n",
       " '1,962',\n",
       " '8',\n",
       " '384',\n",
       " '8',\n",
       " '351']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "matches=[]\n",
    "matches.append(match.text)\n",
    "matches.append(point.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    \n",
    "    matches.append(i.text)\n",
    "    \n",
    "    \n",
    "matches[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8829488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                            167                            '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "first_rating.text.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef55488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            167                            ',\n",
       " '123',\n",
       " '118',\n",
       " '100',\n",
       " '97',\n",
       " '92',\n",
       " '78',\n",
       " '65',\n",
       " '48',\n",
       " '44']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "rating.append(first_rating.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688ffcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca8f6ec",
   "metadata": {},
   "source": [
    "# Top 10 women’s ODI Batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d378af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22c9ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc0fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37491145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alyssa Healy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_player=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "first_player.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abf3cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy',\n",
       " 'Natalie Sciver',\n",
       " 'Beth Mooney',\n",
       " 'Laura Wolvaardt',\n",
       " 'Meg Lanning',\n",
       " 'Rachael Haynes',\n",
       " 'Amy Satterthwaite',\n",
       " 'Smriti Mandhana',\n",
       " 'Tammy Beaumont',\n",
       " 'Ellyse Perry']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player=[]\n",
    "player.append(first_player.text)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    player.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1df4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAUS\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_team=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "y=first_team.text.split(\" \")[0]\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d416be41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nAUS\\n                            785\\n',\n",
       " 'ENG',\n",
       " 'AUS',\n",
       " 'SA',\n",
       " 'AUS',\n",
       " 'AUS',\n",
       " 'NZ',\n",
       " 'IND',\n",
       " 'ENG',\n",
       " 'AUS']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "team.append(first_team.text)\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "861e2fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'785'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "first_rating=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "f=first_rating.text\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d10a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['785', '750', '748', '713', '710', '701', '681', '669', '659', '642']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rating=[]\n",
    "rating.append(f)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1a0921b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>\\n\\nAUS\\n                            785\\n</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player                                        team Rating\n",
       "0       Alyssa Healy  \\n\\nAUS\\n                            785\\n    785\n",
       "1     Natalie Sciver                                         ENG    750\n",
       "2        Beth Mooney                                         AUS    748\n",
       "3    Laura Wolvaardt                                          SA    713\n",
       "4        Meg Lanning                                         AUS    710\n",
       "5     Rachael Haynes                                         AUS    701\n",
       "6  Amy Satterthwaite                                          NZ    681\n",
       "7    Smriti Mandhana                                         IND    669\n",
       "8     Tammy Beaumont                                         ENG    659\n",
       "9       Ellyse Perry                                         AUS    642"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'player':player,'team':team,'Rating':rating})\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241f493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22e9dd59",
   "metadata": {},
   "source": [
    "# CNBC NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87fe1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a84a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66eb9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61d28646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nio can rebound in second half on a strong product pipeline, Morgan Stanley says',\n",
       " 'Bitcoin falls below $19,000 again as pressure mounts on crypto firms',\n",
       " 'Buy the Warner Bros. Discovery dip as shares can nearly double, Benchmark says',\n",
       " 'North Korea is likely culprit behind $100 million crypto heist, researchers say',\n",
       " 'French oil major ramps up discount on gasoline prices for millions of motorists',\n",
       " \"China's Xi arrives in Hong Kong in his first trip off the mainland since the onset of the pandemic\",\n",
       " 'Treasury yields nudge lower as market participants track economic data',\n",
       " 'Singapore’s unemployment has dropped close to pre-Covid levels, minister says',\n",
       " \"'Everything was going fine between us' Putin says of NATO expansion; Russian forces withdraw from Snake Island\",\n",
       " 'In China, more and more people want to save money as job worries grow',\n",
       " 'Coinbase seeks licenses in Europe as it looks to ramp up growth outside the U.S.',\n",
       " \"Here's what's hot — and what's not — in fintech right now\",\n",
       " \"Europe markets decline as recession concerns persist; Germany's Uniper down 14%\",\n",
       " 'Grayscale sues SEC after rejection of bid to turn largest bitcoin fund into ETF',\n",
       " 'China continues to snap up Russian coal at steep discounts',\n",
       " 'Goldman says buy these global stocks to play a $900 billion EV opportunity',\n",
       " 'China Shenzhen stocks rise as data shows factory activity grew; Asia stocks slip',\n",
       " \"Cramer's lightning round: I prefer Deere over Nutrien right here\",\n",
       " 'Cramer warns investors not to group all stocks of the same sector together ',\n",
       " \"Cramer: Charts suggest the recent commodities boom 'is not long for the world'\",\n",
       " 'Palantir CEO Alex Karp on fighting with Peter Thiel and progressives ',\n",
       " 'Spirit delays merger shareholder vote before meeting to continue deal talks ',\n",
       " \"Pinterest improving boards to help people ‘take more action,' new CEO Ready says\",\n",
       " 'Best trades on CNBC Wednesday: Find bargains among megacap tech stocks',\n",
       " 'Stock futures fall as S&P 500 tracks for worst first half since 1970',\n",
       " \"Judge lifts Trump's contempt order in New York civil probe\",\n",
       " \"CoinFlex probably won't resume withdrawals Thursday as planned, says CEO\",\n",
       " 'Amazon wants us to believe the robots are coming. But how useful will they be?',\n",
       " 'RH shares slide after company lowers its outlook for the year',\n",
       " 'This former financial advisor now educates advisors on crypto']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline=[]\n",
    "\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text.replace(\"Ago\",\"\"))\n",
    "    \n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a4eb667f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20 Min Ago',\n",
       " '27 Min Ago',\n",
       " '43 Min Ago',\n",
       " '2 Hours Ago',\n",
       " '2 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '6 Hours Ago',\n",
       " '6 Hours Ago',\n",
       " '6 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '14 Hours Ago',\n",
       " '14 Hours Ago',\n",
       " '14 Hours Ago',\n",
       " '15 Hours Ago',\n",
       " '15 Hours Ago']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "for i in soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "    \n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8b6773b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/pro/',\n",
       " 'https://www.cnbc.com/2022/06/30/bitcoin-falls-below-19000-again-as-pressure-mounts-on-crypto-firms.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/06/30/north-korea-likely-behind-100-million-horizon-crypto-hack-experts.html',\n",
       " 'https://www.cnbc.com/2022/06/30/oil-major-totalenergies-to-provide-fuel-discount-at-highway-stations.html',\n",
       " 'https://www.cnbc.com/2022/06/30/chinas-xi-arrives-in-hong-kong-in-first-trip-off-mainland-since-pandemic.html',\n",
       " 'https://www.cnbc.com/2022/06/30/us-bonds-treasury-yields-in-focus-amid-economic-data-auctions.html',\n",
       " 'https://www.cnbc.com/2022/06/30/singapores-unemployment-close-to-pre-covid-levels-says-minister.html',\n",
       " 'https://www.cnbc.com/2022/06/30/russia-ukraine-live-updates.html',\n",
       " 'https://www.cnbc.com/2022/06/30/pboc-chinese-plans-to-save-hit-a-record-high-in-q2-job-concerns-rise.html',\n",
       " 'https://www.cnbc.com/2022/06/30/coinbase-seeks-europe-licenses-in-bid-to-expand-growth-outside-us.html',\n",
       " 'https://www.cnbc.com/2022/06/30/heres-whats-hot-and-whats-not-in-fintech-right-now.html',\n",
       " 'https://www.cnbc.com/2022/06/30/european-markets-open-to-close-as-recession-concerns-persist.html',\n",
       " 'https://www.cnbc.com/2022/06/30/grayscale-sues-sec-after-rejected-bid-to-turn-bitcoin-fund-into-etf.html',\n",
       " 'https://www.cnbc.com/2022/06/30/china-snaps-up-russian-coal-at-deep-discounts-as-ukraine-war-continues.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/06/30/asia-markets-china-pmi-data-stocks-currencies-oil.html',\n",
       " 'https://www.cnbc.com/2022/06/29/cramers-lightning-round-i-prefer-deere-over-nutrien-right-here.html',\n",
       " 'https://www.cnbc.com/2022/06/29/cramer-warns-investors-not-to-group-all-stocks-of-the-same-sector-together-no-two-stocks-are-truly-alike.html',\n",
       " 'https://www.cnbc.com/2022/06/29/cramer-charts-suggest-recent-commodities-boom-will-come-down-long-term.html',\n",
       " 'https://www.cnbc.com/2022/06/29/palantir-ceo-karp-on-fighting-with-peter-thiel-and-progressives.html',\n",
       " 'https://www.cnbc.com/2022/06/29/spirit-airlines-delays-shareholder-vote-on-frontier-deal-to-july-8.html',\n",
       " 'https://www.cnbc.com/2022/06/29/pinterest-improving-boards-to-help-people-take-more-action-ceo-says.html',\n",
       " '/pro/',\n",
       " 'https://www.cnbc.com/2022/06/29/stock-market-futures-open-to-close-news.html',\n",
       " 'https://www.cnbc.com/2022/06/29/judge-lifts-trump-contempt-order-in-new-york-civil-probe.html',\n",
       " 'https://www.cnbc.com/2022/06/29/coinflex-ceo-unlikely-to-resume-withdrawals-thursday.html',\n",
       " 'https://www.cnbc.com/2022/06/29/amazon-remars-robots-are-here-but-they-still-cant-do-much.html',\n",
       " 'https://www.cnbc.com/2022/06/29/rh-shares-slide-after-company-lowers-its-outlook-for-the-year.html',\n",
       " 'https://www.cnbc.com/2022/06/29/this-former-financial-advisor-now-educates-advisors-on-crypto.html']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_link=[]\n",
    "for i in soup.find_all('li',class_=\"LatestNews-item\"):\n",
    "    news_link.append(i.find(\"a\")['href'])\n",
    "    \n",
    "news_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd048df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(news_link),len(time),len(headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a0f2fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>NEWS LINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nio can rebound in second half on a strong pro...</td>\n",
       "      <td>20 Min Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin falls below $19,000 again as pressure ...</td>\n",
       "      <td>27 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/bitcoin-falls-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buy the Warner Bros. Discovery dip as shares c...</td>\n",
       "      <td>43 Min Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Korea is likely culprit behind $100 mill...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/north-korea-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French oil major ramps up discount on gasoline...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/oil-major-tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China's Xi arrives in Hong Kong in his first t...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/chinas-xi-arri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Treasury yields nudge lower as market particip...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/us-bonds-treas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Singapore’s unemployment has dropped close to ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/singapores-une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'Everything was going fine between us' Putin s...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In China, more and more people want to save mo...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/pboc-chinese-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Coinbase seeks licenses in Europe as it looks ...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/coinbase-seeks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here's what's hot — and what's not — in fintec...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/heres-whats-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Europe markets decline as recession concerns p...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grayscale sues SEC after rejection of bid to t...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/grayscale-sues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>China continues to snap up Russian coal at ste...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/china-snaps-up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Goldman says buy these global stocks to play a...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>China Shenzhen stocks rise as data shows facto...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/30/asia-markets-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cramer's lightning round: I prefer Deere over ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cramer warns investors not to group all stocks...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/cramer-warns-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cramer: Charts suggest the recent commodities ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/cramer-charts-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Palantir CEO Alex Karp on fighting with Peter ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/palantir-ceo-k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Spirit delays merger shareholder vote before m...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/spirit-airline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pinterest improving boards to help people ‘tak...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/pinterest-impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best trades on CNBC Wednesday: Find bargains a...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Stock futures fall as S&amp;P 500 tracks for worst...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/stock-market-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Judge lifts Trump's contempt order in New York...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/judge-lifts-tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CoinFlex probably won't resume withdrawals Thu...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/coinflex-ceo-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Amazon wants us to believe the robots are comi...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/amazon-remars-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RH shares slide after company lowers its outlo...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/rh-shares-slid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This former financial advisor now educates adv...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/29/this-former-fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   Nio can rebound in second half on a strong pro...    20 Min Ago   \n",
       "1   Bitcoin falls below $19,000 again as pressure ...    27 Min Ago   \n",
       "2   Buy the Warner Bros. Discovery dip as shares c...    43 Min Ago   \n",
       "3   North Korea is likely culprit behind $100 mill...   2 Hours Ago   \n",
       "4   French oil major ramps up discount on gasoline...   2 Hours Ago   \n",
       "5   China's Xi arrives in Hong Kong in his first t...   3 Hours Ago   \n",
       "6   Treasury yields nudge lower as market particip...   4 Hours Ago   \n",
       "7   Singapore’s unemployment has dropped close to ...   4 Hours Ago   \n",
       "8   'Everything was going fine between us' Putin s...   4 Hours Ago   \n",
       "9   In China, more and more people want to save mo...   5 Hours Ago   \n",
       "10  Coinbase seeks licenses in Europe as it looks ...   6 Hours Ago   \n",
       "11  Here's what's hot — and what's not — in fintec...   6 Hours Ago   \n",
       "12  Europe markets decline as recession concerns p...   6 Hours Ago   \n",
       "13  Grayscale sues SEC after rejection of bid to t...   7 Hours Ago   \n",
       "14  China continues to snap up Russian coal at ste...  10 Hours Ago   \n",
       "15  Goldman says buy these global stocks to play a...  11 Hours Ago   \n",
       "16  China Shenzhen stocks rise as data shows facto...  11 Hours Ago   \n",
       "17  Cramer's lightning round: I prefer Deere over ...  12 Hours Ago   \n",
       "18  Cramer warns investors not to group all stocks...  12 Hours Ago   \n",
       "19  Cramer: Charts suggest the recent commodities ...  12 Hours Ago   \n",
       "20  Palantir CEO Alex Karp on fighting with Peter ...  12 Hours Ago   \n",
       "21  Spirit delays merger shareholder vote before m...  12 Hours Ago   \n",
       "22  Pinterest improving boards to help people ‘tak...  12 Hours Ago   \n",
       "23  Best trades on CNBC Wednesday: Find bargains a...  13 Hours Ago   \n",
       "24  Stock futures fall as S&P 500 tracks for worst...  13 Hours Ago   \n",
       "25  Judge lifts Trump's contempt order in New York...  14 Hours Ago   \n",
       "26  CoinFlex probably won't resume withdrawals Thu...  14 Hours Ago   \n",
       "27  Amazon wants us to believe the robots are comi...  14 Hours Ago   \n",
       "28  RH shares slide after company lowers its outlo...  15 Hours Ago   \n",
       "29  This former financial advisor now educates adv...  15 Hours Ago   \n",
       "\n",
       "                                            NEWS LINK  \n",
       "0                                               /pro/  \n",
       "1   https://www.cnbc.com/2022/06/30/bitcoin-falls-...  \n",
       "2                                               /pro/  \n",
       "3   https://www.cnbc.com/2022/06/30/north-korea-li...  \n",
       "4   https://www.cnbc.com/2022/06/30/oil-major-tota...  \n",
       "5   https://www.cnbc.com/2022/06/30/chinas-xi-arri...  \n",
       "6   https://www.cnbc.com/2022/06/30/us-bonds-treas...  \n",
       "7   https://www.cnbc.com/2022/06/30/singapores-une...  \n",
       "8   https://www.cnbc.com/2022/06/30/russia-ukraine...  \n",
       "9   https://www.cnbc.com/2022/06/30/pboc-chinese-p...  \n",
       "10  https://www.cnbc.com/2022/06/30/coinbase-seeks...  \n",
       "11  https://www.cnbc.com/2022/06/30/heres-whats-ho...  \n",
       "12  https://www.cnbc.com/2022/06/30/european-marke...  \n",
       "13  https://www.cnbc.com/2022/06/30/grayscale-sues...  \n",
       "14  https://www.cnbc.com/2022/06/30/china-snaps-up...  \n",
       "15                                              /pro/  \n",
       "16  https://www.cnbc.com/2022/06/30/asia-markets-c...  \n",
       "17  https://www.cnbc.com/2022/06/29/cramers-lightn...  \n",
       "18  https://www.cnbc.com/2022/06/29/cramer-warns-i...  \n",
       "19  https://www.cnbc.com/2022/06/29/cramer-charts-...  \n",
       "20  https://www.cnbc.com/2022/06/29/palantir-ceo-k...  \n",
       "21  https://www.cnbc.com/2022/06/29/spirit-airline...  \n",
       "22  https://www.cnbc.com/2022/06/29/pinterest-impr...  \n",
       "23                                              /pro/  \n",
       "24  https://www.cnbc.com/2022/06/29/stock-market-f...  \n",
       "25  https://www.cnbc.com/2022/06/29/judge-lifts-tr...  \n",
       "26  https://www.cnbc.com/2022/06/29/coinflex-ceo-u...  \n",
       "27  https://www.cnbc.com/2022/06/29/amazon-remars-...  \n",
       "28  https://www.cnbc.com/2022/06/29/rh-shares-slid...  \n",
       "29  https://www.cnbc.com/2022/06/29/this-former-fi...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Headline':headline,'Time':time,'NEWS LINK':news_link})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29aa13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9586292e",
   "metadata": {},
   "source": [
    "# MOST DOWNLOADED ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb7f9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a9255dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0543af53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c5fa91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3330c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_title=[]\n",
    "\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    paper_title.append(i.text)\n",
    "    \n",
    "paper_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1e9be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98930bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_date=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    publish_date.append(i.text)\n",
    "    \n",
    "publish_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f2bcb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[]\n",
    "\n",
    "for i in soup.find_all('a',class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    url.append(i['href'])\n",
    "    \n",
    "url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168f7ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(paper_title),len(authors),len(publish_date),len(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1569d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Paper Title':paper_title,'Authors':authors,'Published Date':publish_date,'Paper URL':url})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eea83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52767af3",
   "metadata": {},
   "source": [
    "# DINE OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61763c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c2e004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d5d54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "52e51736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle BarbequeConnaught Place, Central Delhi',\n",
       " 'Jungle Jamboree3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Castle BarbequePacific Mall,Tagore Garden, West Delhi',\n",
       " 'Cafe KnoshThe Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'The Barbeque CompanyGardens Galleria,Sector 38A, Noida',\n",
       " 'India GrillHilton Garden Inn,Saket, South Delhi',\n",
       " 'Delhi BarbequeTaurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'The Monarch - Bar Be Que VillageIndirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'World CafeVibe by The Lalit Traveller,Sector 35, Faridabad',\n",
       " 'Indian Grill RoomSuncity Business Tower,Golf Course Road, Gurgaon',\n",
       " 'Mad 4 Bar B QueSector 29, Faridabad',\n",
       " 'Barbeque 29NIT, Faridabad',\n",
       " 'GlasshouseDoubleTree By Hilton Gurugram Baani Square,Sector 50, Gurgaon']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_name=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    \n",
    "    r_name.append(i.text)\n",
    "\n",
    "r_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad2a0b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' North Indian, Chinese',\n",
       " ' North Indian, Asian, Italian',\n",
       " ' Chinese, North Indian',\n",
       " ' Italian, Continental',\n",
       " ' North Indian, Chinese',\n",
       " ' North Indian, Italian',\n",
       " ' North Indian',\n",
       " ' North Indian',\n",
       " ' North Indian, Italian',\n",
       " ' North Indian, Mughlai',\n",
       " ' North Indian',\n",
       " ' North Indian, Mughlai, Desserts, Beverages',\n",
       " ' European, Italian, Asian, Continental']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine=[]\n",
    "\n",
    "#for i in soup.find_all('span',class_=\"more\"):\n",
    " #   cuisine.append(i.find_all(\"a\").text)\n",
    "for i in soup.find_all(\"span\", class_=\"double-line-ellipsis\"):\n",
    "\n",
    "    cuisine.append(i.text.split('|')[1])  \n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "af2fbaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Vibe by The Lalit Traveller,Sector 35, Faridabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon',\n",
       " 'Sector 29, Faridabad',\n",
       " 'NIT, Faridabad',\n",
       " 'DoubleTree By Hilton Gurugram Baani Square,Sector 50, Gurgaon']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "707cdd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.5',\n",
       " '3.9',\n",
       " '3.9',\n",
       " '4.3',\n",
       " '4',\n",
       " '3.9',\n",
       " '3.7',\n",
       " '3.8',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '3.6',\n",
       " '4.2',\n",
       " '4']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68cad6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/h/c/p3643-144497865356209fdd65746.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/v/f/p52501-16006856545f68865616659.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/p/y/p12366-1466935020576fa6ecdc359.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/n/t/p43488-1647323111623027e763947.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/w/r/p58842-15624171585d209806d9143.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/m/a/p9875-1645177960620f6c68ecfef.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n",
    "    \n",
    "images    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "27599a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restuarant name</th>\n",
       "      <th>Location</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>North Indian, Mughlai, Desserts, Beverages</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>European, Italian, Asian, Continental</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restuarant name   \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3   Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4   The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad   \n",
       "11                          Barbeque 29NIT, Faridabad   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                             Location  \\\n",
       "0                      Connaught Place, Central Delhi   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                  Gardens Galleria,Sector 38A, Noida   \n",
       "5                Hilton Garden Inn,Saket, South Delhi   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "10                               Sector 29, Faridabad   \n",
       "11                                     NIT, Faridabad   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...   \n",
       "\n",
       "                                        cuisine Rating  \\\n",
       "0                         North Indian, Chinese    3.5   \n",
       "1                  North Indian, Asian, Italian    3.9   \n",
       "2                         Chinese, North Indian    3.9   \n",
       "3                          Italian, Continental    4.3   \n",
       "4                         North Indian, Chinese      4   \n",
       "5                         North Indian, Italian    3.9   \n",
       "6                                  North Indian    3.7   \n",
       "7                                  North Indian    3.8   \n",
       "8                         North Indian, Italian    4.3   \n",
       "9                         North Indian, Mughlai    4.3   \n",
       "10                                 North Indian    3.6   \n",
       "11   North Indian, Mughlai, Desserts, Beverages    4.2   \n",
       "12        European, Italian, Asian, Continental      4   \n",
       "\n",
       "                                               Images  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Restuarant name ':r_name,'Location':location,'cuisine':cuisine,'Rating':rating,'Images':images})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415a03a",
   "metadata": {},
   "source": [
    "# GOOGLE SCHOLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4aa3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0754652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85dde85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa951b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " '31.',\n",
       " '32.',\n",
       " '33.',\n",
       " '34.',\n",
       " '35.',\n",
       " '36.',\n",
       " '37.',\n",
       " '38.',\n",
       " '39.',\n",
       " '40.',\n",
       " '41.',\n",
       " '42.',\n",
       " '43.',\n",
       " '44.',\n",
       " '45.',\n",
       " '46.',\n",
       " '47.',\n",
       " '48.',\n",
       " '49.',\n",
       " '50.',\n",
       " '51.',\n",
       " '52.',\n",
       " '53.',\n",
       " '54.',\n",
       " '55.',\n",
       " '56.',\n",
       " '57.',\n",
       " '58.',\n",
       " '59.',\n",
       " '60.',\n",
       " '61.',\n",
       " '62.',\n",
       " '63.',\n",
       " '64.',\n",
       " '65.',\n",
       " '66.',\n",
       " '67.',\n",
       " '68.',\n",
       " '69.',\n",
       " '70.',\n",
       " '71.',\n",
       " '72.',\n",
       " '73.',\n",
       " '74.',\n",
       " '75.',\n",
       " '76.',\n",
       " '77.',\n",
       " '78.',\n",
       " '79.',\n",
       " '80.',\n",
       " '81.',\n",
       " '82.',\n",
       " '83.',\n",
       " '84.',\n",
       " '85.',\n",
       " '86.',\n",
       " '87.',\n",
       " '88.',\n",
       " '89.',\n",
       " '90.',\n",
       " '91.',\n",
       " '92.',\n",
       " '93.',\n",
       " '94.',\n",
       " '95.',\n",
       " '96.',\n",
       " '97.',\n",
       " '98.',\n",
       " '99.',\n",
       " '100.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "    \n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2a95055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature',\n",
       " 'The New England Journal of Medicine',\n",
       " 'Science',\n",
       " 'IEEE/CVF Conference on Computer Vision and Pattern Recognition',\n",
       " 'The Lancet',\n",
       " 'Advanced Materials',\n",
       " 'Nature Communications',\n",
       " 'Cell',\n",
       " 'International Conference on Learning Representations',\n",
       " 'Neural Information Processing Systems',\n",
       " 'JAMA',\n",
       " 'Chemical Reviews',\n",
       " 'Proceedings of the National Academy of Sciences',\n",
       " 'Angewandte Chemie',\n",
       " 'Chemical Society Reviews',\n",
       " 'Journal of the American Chemical Society',\n",
       " 'IEEE/CVF International Conference on Computer Vision',\n",
       " 'Nucleic Acids Research',\n",
       " 'International Conference on Machine Learning',\n",
       " 'Nature Medicine',\n",
       " 'Renewable and Sustainable Energy Reviews',\n",
       " 'Science of The Total Environment',\n",
       " 'Advanced Energy Materials',\n",
       " 'Journal of Clinical Oncology',\n",
       " 'ACS Nano',\n",
       " 'Journal of Cleaner Production',\n",
       " 'Advanced Functional Materials',\n",
       " 'Physical Review Letters',\n",
       " 'Scientific Reports',\n",
       " 'The Lancet Oncology',\n",
       " 'Energy & Environmental Science',\n",
       " 'IEEE Access',\n",
       " 'PLoS ONE',\n",
       " 'Science Advances',\n",
       " 'Journal of the American College of Cardiology',\n",
       " 'Applied Catalysis B: Environmental',\n",
       " 'Nature Genetics',\n",
       " 'BMJ',\n",
       " 'Circulation',\n",
       " 'European Conference on Computer Vision',\n",
       " 'International Journal of Molecular Sciences',\n",
       " 'Nature Materials',\n",
       " 'Chemical engineering journal',\n",
       " 'AAAI Conference on Artificial Intelligence',\n",
       " 'Journal of Materials Chemistry A',\n",
       " 'ACS Applied Materials & Interfaces',\n",
       " 'Nature Biotechnology',\n",
       " 'The Lancet Infectious Diseases',\n",
       " 'Frontiers in Immunology',\n",
       " 'Applied Energy',\n",
       " 'Nano Energy',\n",
       " 'Nature Energy',\n",
       " 'Meeting of the Association for Computational Linguistics (ACL)',\n",
       " 'The Astrophysical Journal',\n",
       " 'Gastroenterology',\n",
       " 'Nature Methods',\n",
       " 'IEEE Transactions on Pattern Analysis and Machine Intelligence',\n",
       " 'Cochrane Database of Systematic Reviews',\n",
       " 'Blood',\n",
       " 'Neuron',\n",
       " 'Nano Letters',\n",
       " 'Morbidity and Mortality Weekly Report',\n",
       " 'European Heart Journal',\n",
       " 'Nature Nanotechnology',\n",
       " 'ACS Catalysis',\n",
       " 'Nature Neuroscience',\n",
       " 'American Economic Review',\n",
       " 'Journal of High Energy Physics',\n",
       " 'IEEE Communications Surveys & Tutorials',\n",
       " 'Annals of Oncology',\n",
       " 'Nutrients',\n",
       " 'Accounts of Chemical Research',\n",
       " 'Immunity',\n",
       " 'Environmental Science & Technology',\n",
       " 'Nature Reviews. Molecular Cell Biology',\n",
       " 'Gut',\n",
       " 'Physical Review D',\n",
       " 'ACS Energy Letters',\n",
       " 'Monthly Notices of the Royal Astronomical Society',\n",
       " 'Conference on Empirical Methods in Natural Language Processing (EMNLP)',\n",
       " 'Clinical Infectious Diseases',\n",
       " 'Cell Metabolism',\n",
       " 'Nature Reviews Immunology',\n",
       " 'Joule',\n",
       " 'Nature Photonics',\n",
       " 'International Journal of Environmental Research and Public Health',\n",
       " 'Environmental Pollution',\n",
       " 'Computers in Human Behavior',\n",
       " 'Frontiers in Microbiology',\n",
       " 'Nature Physics',\n",
       " 'Small',\n",
       " 'Cell Reports',\n",
       " 'Molecular Cell',\n",
       " 'Clinical Cancer Research',\n",
       " 'Bioresource Technology',\n",
       " 'Journal of Business Research',\n",
       " 'Molecular Cancer',\n",
       " 'Sensors',\n",
       " 'Nature Climate Change',\n",
       " 'IEEE Internet of Things Journal']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "\n",
    "publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "516350b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444',\n",
       " '432',\n",
       " '401',\n",
       " '389',\n",
       " '354',\n",
       " '312',\n",
       " '307',\n",
       " '300',\n",
       " '286',\n",
       " '278',\n",
       " '267',\n",
       " '265',\n",
       " '256',\n",
       " '245',\n",
       " '244',\n",
       " '242',\n",
       " '239',\n",
       " '238',\n",
       " '237',\n",
       " '235',\n",
       " '227',\n",
       " '225',\n",
       " '220',\n",
       " '213',\n",
       " '211',\n",
       " '211',\n",
       " '210',\n",
       " '207',\n",
       " '206',\n",
       " '202',\n",
       " '202',\n",
       " '200',\n",
       " '198',\n",
       " '197',\n",
       " '195',\n",
       " '192',\n",
       " '191',\n",
       " '190',\n",
       " '189',\n",
       " '186',\n",
       " '183',\n",
       " '181',\n",
       " '181',\n",
       " '180',\n",
       " '178',\n",
       " '177',\n",
       " '175',\n",
       " '173',\n",
       " '173',\n",
       " '173',\n",
       " '172',\n",
       " '170',\n",
       " '169',\n",
       " '167',\n",
       " '166',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '164',\n",
       " '164',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '162',\n",
       " '160',\n",
       " '160',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '158',\n",
       " '158',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '154',\n",
       " '153',\n",
       " '153',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '151',\n",
       " '151',\n",
       " '150',\n",
       " '149',\n",
       " '149',\n",
       " '146',\n",
       " '146',\n",
       " '145',\n",
       " '145',\n",
       " '145',\n",
       " '144',\n",
       " '144']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " h5index=[]\n",
    "for i in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "     h5index.append(i.text)\n",
    "        \n",
    "h5index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79e94ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667',\n",
       " '780',\n",
       " '614',\n",
       " '627',\n",
       " '635',\n",
       " '418',\n",
       " '428',\n",
       " '505',\n",
       " '533',\n",
       " '436',\n",
       " '425',\n",
       " '444',\n",
       " '364',\n",
       " '332',\n",
       " '386',\n",
       " '344',\n",
       " '415',\n",
       " '550',\n",
       " '421',\n",
       " '389',\n",
       " '324',\n",
       " '311',\n",
       " '300',\n",
       " '315',\n",
       " '277',\n",
       " '273',\n",
       " '280',\n",
       " '294',\n",
       " '274',\n",
       " '329',\n",
       " '290',\n",
       " '303',\n",
       " '278',\n",
       " '294',\n",
       " '276',\n",
       " '246',\n",
       " '297',\n",
       " '307',\n",
       " '301',\n",
       " '321',\n",
       " '253',\n",
       " '265',\n",
       " '224',\n",
       " '296',\n",
       " '220',\n",
       " '223',\n",
       " '315',\n",
       " '296',\n",
       " '228',\n",
       " '217',\n",
       " '232',\n",
       " '314',\n",
       " '304',\n",
       " '234',\n",
       " '254',\n",
       " '296',\n",
       " '293',\n",
       " '243',\n",
       " '229',\n",
       " '231',\n",
       " '207',\n",
       " '302',\n",
       " '265',\n",
       " '264',\n",
       " '220',\n",
       " '248',\n",
       " '263',\n",
       " '220',\n",
       " '304',\n",
       " '243',\n",
       " '214',\n",
       " '211',\n",
       " '242',\n",
       " '214',\n",
       " '340',\n",
       " '235',\n",
       " '217',\n",
       " '212',\n",
       " '194',\n",
       " '249',\n",
       " '278',\n",
       " '211',\n",
       " '292',\n",
       " '233',\n",
       " '228',\n",
       " '225',\n",
       " '222',\n",
       " '214',\n",
       " '225',\n",
       " '222',\n",
       " '196',\n",
       " '205',\n",
       " '202',\n",
       " '201',\n",
       " '190',\n",
       " '233',\n",
       " '209',\n",
       " '201',\n",
       " '228',\n",
       " '212']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5median=[]\n",
    "for i in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5median.append(i.text)\n",
    "    \n",
    "h5median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "547003c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rank':rank,'Publication':publication,'h5-index':h5index,'h5-median':h5median})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66921842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
